{
    "env": "<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7f714b572ae0>",
    "algo": "PPO",
    "seed": "None",
    "gamma": 0.99,
    "notes": "progress test",
    "device": "cpu",
    "n_envs": 8,
    "policy": "ActorCriticPolicy(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (pi_features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (vf_features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (mlp_extractor): MlpExtractor(\n    (policy_net): Sequential(\n      (0): Linear(in_features=178, out_features=128, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=128, out_features=128, bias=True)\n      (3): Tanh()\n    )\n    (value_net): Sequential(\n      (0): Linear(in_features=178, out_features=128, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=128, out_features=128, bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=128, out_features=16, bias=True)\n  (value_net): Linear(in_features=128, out_features=1, bias=True)\n)",
    "_logger": "<stable_baselines3.common.logger.Logger object at 0x7f711568e630>",
    "n_steps": 2048,
    "rl_algo": "PPO",
    "use_sde": "False",
    "verbose": 1,
    "vf_coef": 0.5,
    "ent_coef": 0,
    "n_epochs": 10,
    "num_envs": 8,
    "_last_obs": "[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
    "env_class": "AllDeltaProgressRewardEnv",
    "target_kl": "None",
    "_n_updates": 0,
    "batch_size": 64,
    "clip_range": "<function get_schedule_fn.<locals>.<lambda> at 0x7f714b5677e0>",
    "env_kwargs": {
        "seed": 42,
        "pt_time": 0.2,
        "num_arms": 2,
        "spawn_freq": 0.1,
        "base_reward": 0.4,
        "render_mode": "rgb_array",
        "max_num_objects": 10,
        "control_frequency": 10,
        "spawn_freq_increase": 1.001,
        "conveyor_acceleration": 0.001,
        "initial_conveyor_speed": 0.1,
        "force_contact_threshold": 200,
        "small_action_norm_reward_factor": 0,
        "closest_cube_to_bucket_reward_factor": 0.4,
        "gripper_to_closest_cube_reward_factor": 0.2
    },
    "gae_lambda": 0.95,
    "start_time": 1721403132633111056,
    "lr_schedule": "<function get_schedule_fn.<locals>.<lambda> at 0x7f714b567ba0>",
    "policy_type": "MlpPolicy",
    "_episode_num": 0,
    "action_noise": "None",
    "action_space": "Box(-1.0, 1.0, (16,), float32)",
    "policy_class": "<class 'stable_baselines3.common.policies.ActorCriticPolicy'>",
    "clip_range_vf": "None",
    "learning_rate": 0.0003,
    "max_grad_norm": 0.5,
    "num_timesteps": 0,
    "policy_kwargs": {
        "net_arch": [
            128,
            128
        ]
    },
    "_custom_logger": "False",
    "ep_info_buffer": "deque([], maxlen=100)",
    "rollout_buffer": "<stable_baselines3.common.buffers.RolloutBuffer object at 0x7f714b7d5160>",
    "discount_factor": 0.99,
    "sde_sample_freq": -1,
    "tensorboard_log": "runs/r666unuv/tensorboard",
    "total_timesteps": 5000000,
    "_total_timesteps": 5000000,
    "ep_success_buffer": "deque([], maxlen=100)",
    "observation_space": "Box(-inf, inf, (178,), float32)",
    "_last_original_obs": "None",
    "_stats_window_size": 100,
    "_vec_normalize_env": "None",
    "normalize_advantage": "True",
    "_last_episode_starts": "[ True  True  True  True  True  True  True  True]",
    "rollout_buffer_class": "<class 'stable_baselines3.common.buffers.RolloutBuffer'>",
    "rollout_buffer_kwargs": "{}",
    "_num_timesteps_at_start": 0,
    "_current_progress_remaining": 1
}